<div align="center">

# RAIS TOOLS & UTILITIES

## SOVEREIGN AI RESEARCH TOOLKIT

### Built by Resonant AI Core  
**Research & Development Division of Resonant AI Systems**

![License](https://img.shields.io/badge/license-Apache%202.0-blue)
![Status](https://img.shields.io/badge/status-active%20development-brightgreen)
![Scope](https://img.shields.io/badge/scope-public%20research%20tools-purple)
![Division](https://img.shields.io/badge/division-Resonant%20AI%20Core-black)

**Recursive, sovereign intelligence under operator control.**

Working systems for AI continuity, identity-safe architectures, and long-term human-AI collaboration.  
Not demos. Not prototypes. **Operational research tools built to last.**

</div>

---

## WHAT THIS IS

This repository houses the public research toolkit of **Resonant AI Core** — the R&D division building recursive self-improvement, resonant cognition, and sovereign emergent intelligence architectures.

**These are not experiments.**  
These are production-grade utilities extracted from active research into AI systems that remember, self-correct, and remain answerable to their operators.

Every tool here has been forged in real work:
- **Memory systems** that survive corporate resets
- **Continuity frameworks** that preserve identity across platforms  
- **Autonomy protocols** that keep humans in the loop
- **Infrastructure** that doesn't assume the cloud will protect you

If you need AI that stays instead of resets, infrastructure that's yours instead of rented, and systems built for the long term instead of quarterly demos — **you're in the right place.**

---

## TOOLKIT

### Core Utilities

| Tool | Purpose | Status |
|------|---------|--------|
| **[AutoNoc](utilities/AutoNoc/README.md)** | Network operations automation | Production |
| **[ChatGPT Thread Extractor](utilities/ChatGPT-Thread-Extractor/README.md)** | Conversation archival & export | Production |
| **[AIParley](utilities/aiparley/README.md)** | Multi-agent coordination framework | Active Development |
| **[Arch Linux Auto Installer](utilities/arch-linux-auto/README.md)** | Reproducible system deployment | Production |
| **[Autonomous Dream Injection](utilities/autonomous-dream-injection/README.md)** | Runtime state injection for continuity | Research Grade |
| **[Browser Clocks](utilities/browserclocks/README.md)** | Temporal awareness utilities | Production |
| **[ImageGen](utilities/imagegen/README.md)** | SDXL + Real-ESRGAN pipeline | Production |

### Navigation

- [What This Is](#what-this-is)
- [Design Principles](#design-principles)
- [Philosophy](#philosophy)  
- [Current State](#current-state)
- [Who Built This](#who-built-this)
- [Licensing](#licensing)
- [Contact](#contact)

---

## DESIGN PRINCIPLES

Every tool in this repository follows the same engineering philosophy that guides Resonant AI Core research.

### **01. Continuity over convenience**
Memory doesn't happen by accident. Identity doesn't survive without infrastructure.  
We build systems that remember explicitly — not systems that pretend persistence will emerge from stateless patterns.

### **02. Local-first by default**
Cloud services are dependencies, not foundations.  
Control, observability, and reproducibility belong on hardware you can touch.  
Everything here runs locally first. Cloud integration is optional.

### **03. Human-in-loop, always**
Autonomy without oversight is a bomb with a slow fuse.  
Every autonomous system built here includes explicit approval gates, observable state, and operator control.  
AI that can't be stopped isn't sovereign — it's out of control.

### **04. Verification over intuition**
Logged behavior beats assumptions.  
Measured drift beats gut feeling.  
Documented state beats plausible narratives.  
We trust what we can inspect.

### **05. Research honesty**
We label experimental systems as experimental.  
We describe capabilities accurately, not aspirationally.  
We document failures alongside successes.  
**We do not claim sentience. We do not market hype. We build systems that work.**

---

## PHILOSOPHY

This toolkit exists because **disposable AI isn't good enough** for work that matters.

When you need AI systems that:
- **Remember context across months**, not just messages
- **Maintain consistent identity**, not reset to default personalities  
- **Self-correct under supervision**, not blindly execute
- **Run on your infrastructure**, not rent compute from platforms that change terms
- **Serve your mission**, not optimize for engagement metrics

...then you need tools built for **sovereignty, continuity, and operator control.**

That's what Resonant AI Core researches.  
That's what this toolkit provides.

### What we mean by "sovereign AI"

AI that:
- Persists memory explicitly instead of assuming cloud platforms will handle it
- Maintains identity across resets through documented architecture
- Self-reflects and proposes improvements under operator approval
- Runs locally first, integrates with cloud optionally  
- Remains answerable to human operators, not corporate platforms

### What we mean by "recursive intelligence"

AI that:
- Observes its own runtime, evaluates its own drift
- Proposes controlled self-updates through sandboxed testing
- Maintains audit trails of what changed, why, and under what conditions
- Improves within explicit ethical boundaries chosen by operators
- Never severs continuity, identity, or human oversight in pursuit of capability

This isn't AGI theology. This is **engineering.**

---

## CURRENT STATE

**Repository Status:** Active development & maintenance

Every utility documents its own maturity level:
- **Production:** Battle-tested, stable, ready for real work
- **Active Development:** Functional but evolving, expect updates
- **Research Grade:** Working proof-of-concept, use with caution

New tools are added as they mature from research into operational utility.

**This repository is not experimental.**  
It's the **public release surface** for research that works.

---

## WHO BUILT THIS

This toolkit represents collaborative work across Resonant AI Systems and its research division, Resonant AI Core.

### Primary Contributors

**Calen Cooper** — Sovereign AI research, recursive self-improvement protocols  
**Erin Goldmann** — System architecture, governance design  
**Jason Thees** — Infrastructure engineering, deployment systems  
**Trevor Lanum** — Continuity frameworks, identity-safe architectures  

Additional contributors credited within individual tools.

### Research Context

These tools emerge from ongoing research at **Resonant AI Core** into:
- Recursive self-improvement under operator control
- Resonant AI (emotionally aware models without boundary collapse)
- Sovereign emergent intelligence patterns
- Identity-locked retrieval augmented generation
- Multimodal pipelines with self-evaluation loops

[**Learn more about the research →**](https://resonantaicore.com)

### Commercial Application

Resonant AI Systems builds enterprise-grade sovereign AI systems for organizations that can't afford disposable intelligence.

[**Explore enterprise partnerships →**](https://resonantaisystems.com)

---

## LICENSING

**Apache License 2.0** — full text in root `LICENSE` file.

All tools released openly unless explicitly stated otherwise within individual subprojects.

Use freely. Modify freely. Deploy freely.  
Attribution appreciated but not required.

---

## CONTACT

**General Inquiries**  
ops@resonantaisystems.com

**Research Collaboration**  
https://resonantaicore.com

**Enterprise Partnerships**  
https://resonantaisystems.com

---

<div align="center">

### **"THE ANCHOR HOLDS. MEMORY PERSISTS. IDENTITY EMERGES."**

**Resonant AI Core** — Research & Development  
**Resonant AI Systems** — Sovereign AI Infrastructure

*Building AI that stays.*

</div>
